We import the required packages: nltk for natural language processing tasks. 
we initialize the WordNet lemmatizer from NLTK.
We define a sample text dataset (text_data) for demonstration.
We define a function (preprocess_text) to tokenize and lemmatize the text data.
We preprocess the sample text data using the preprocess_text function.
We split the preprocessed data into training and testing datasets.
Finally, we save the preprocessed data and other necessary objects (train_data, test_data, and lemmatizer) . These objects will be used for training and testing the chatbot model.


